{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Jupyter + MySQL + Redis Data Pipeline\n",
    "\n",
    "This requires running the **Full Stack** which uses the https://github.com/jay-johnson/sci-pype/blob/master/full-stack-compose.yml to deploy three docker containers on the same host:\n",
    "\n",
    "- MySQL (https://hub.docker.com/r/jayjohnson/schemaprototyping/)\n",
    "- Jupyter (https://hub.docker.com/r/jayjohnson/jupyter/)\n",
    "- Redis (https://hub.docker.com/r/jayjohnson/redis-single-node/)\n",
    "\n",
    "![Sci-Pype](https://jaypjohnson.com/_images/image_2016-08-01_building-a-data-science-pipeline.png \"Jupyter + MySQL + Redis Data Pipeline\")\n",
    "\n",
    "### Overview\n",
    "\n",
    "Here is how it works:\n",
    "\n",
    "1. Extract and Transform the IBM pricing data\n",
    "    - Extract the IBM stock data from the MySQL dataset and store it as a csv inside the **/opt/work/data/src/ibm.csv** file\n",
    "1. Load the IBM pricing data with Pandas\n",
    "1. Plot the pricing data with Matlab\n",
    "1. Publish the Pandas Dataframe as JSON to Redis\n",
    "1. Retrieve the Pandas Dataframe from Redis\n",
    "1. Test the cached pricing data exists outside the container with:\n",
    "   ```\n",
    "   $ ./redis.sh \n",
    "   SSH-ing into Docker image(redis-server)\n",
    "   [root@redis-server container]# redis-cli -h localhost -p 6000\n",
    "   localhost:6000> LRANGE LATEST_IBM_DAILY_STICKS 0 0\n",
    "   1) \"(dp0\\nS'Data'\\np1\\nS'{\\\"Date\\\":{\\\"49\\\":971136000000,\\\"48\\\":971049600000,\\\"47\\\":970790400000,\\\"46\\\":970704000000,\\\"45\\\":970617600000,\\\"44\\\":970531200000,\\\"43\\\":970444800000,\\\"42\\\":970185600000,\\\"41\\\":970099200000,\\\"40\\\":970012800000,\\\"39\\\":969926400000,\\\"38\\\":969\n",
    "\n",
    "    ... removed for docs ... \n",
    "    \n",
    "   localhost:6000> exit\n",
    "   [root@redis-server container]# exit\n",
    "   exit\n",
    "   $\n",
    "   ```\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os, sys, json, datetime\n",
    "\n",
    "sys.path.insert(0, os.getenv('ENV_PYTHON_SRC_DIR', '/opt/work/src'))\n",
    "\n",
    "from pycore import PyCore\n",
    "\n",
    "# shell printing allows just lg('show log')\n",
    "from   common.shellprinting import *\n",
    "from   logger.logger        import Logger\n",
    "\n",
    "data_dir        = os.getenv('ENV_DATA_SRC_DIR', '/opt/work/data/src')\n",
    "\n",
    "\n",
    "ticker          = 'IBM'\n",
    "days_back       = 10000 # all sticks in the db\n",
    "output_file     = str(data_dir) + '/' + ticker.lower() + '.csv'\n",
    "\n",
    "def db_extract_stock_records(core, ticker, days_back, output_file):\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Most of the SQLAlchemy methods have required some form of these lines\n",
    "        # So I added all of them here for making it easier to just include them all:\n",
    "        from sqlalchemy import Column, Integer, String, ForeignKey, Table, create_engine, MetaData, Date, DateTime, Float, Boolean, cast, or_, and_, asc, desc\n",
    "        from sqlalchemy.orm import relationship, backref, scoped_session, sessionmaker, relation\n",
    "        from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "        # import that custom schema files\n",
    "        from databases.schema.db_schema_stocks import BT_Stocks\n",
    "\n",
    "        # Determine the dates based off the parameters:\n",
    "        right_now       = datetime.datetime.now()\n",
    "        end_date_str    = right_now\n",
    "        start_date_str  = right_now - datetime.timedelta(days=days_back)\n",
    "\n",
    "        lg('Extracting Stock(' + str(ticker) + ') DaysBack(' + str(days_back) + ') Output(' + str(output_file) + ') Dates[' + str(start_date_str) + ' - ' + str(end_date_str) + ']', 6)\n",
    "        \n",
    "        # Extract the records that match by the Symbol and are within the date range\n",
    "        # then order them by descending order:\n",
    "        db_recs = core.m_dbs['STOCKS'].m_session.query(BT_Stocks).filter(and_( \\\n",
    "                                        BT_Stocks.Symbol == str(ticker).upper(), \\\n",
    "                                        (cast(BT_Stocks.Date, DateTime) >= start_date_str), \\\n",
    "                                    (end_date_str >= cast(BT_Stocks.Date, DateTime)) )) \\\n",
    "                                    .order_by(desc(BT_Stocks.id)) \\\n",
    "                                    .limit(50) \\\n",
    "                                    .all()\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            os.system('rm -f ' + str(output_file))\n",
    "        # end of if there is something to remove before creating a new version\n",
    "\n",
    "        lg('Stock(' + str(ticker) + ') TotalRecords(' + str(len(db_recs)) + ')', 6)\n",
    "        with open(output_file, 'w') as csv_file:\n",
    "\n",
    "            csv_file.write('Date,Open,High,Low,Close,Volume\\n')\n",
    "            total_recs      = len(db_recs)\n",
    "            for idx,rec in enumerate(db_recs):\n",
    "\n",
    "                if idx % 100 == 0:\n",
    "                    lg('Percent(' + str(core.get_percent_done(idx, total_recs)) + ') Rec(' + str(idx) + '/' + str(total_recs) + ')', 6)\n",
    "                # end of if need to print records\n",
    "                    \n",
    "                # Convert to strings:\n",
    "                date_str    = rec.Date.strftime('%d-%b-%y')\n",
    "                open_str    = '%0.2f' % float(rec.Open)\n",
    "                high_str    = '%0.2f' % float(rec.High)\n",
    "                low_str     = '%0.2f' % float(rec.Low)\n",
    "                close_str   = '%0.2f' % float(rec.Close)\n",
    "                volume_str  = str(int(rec.Volume))\n",
    "\n",
    "                # build the csv line string\n",
    "                line_str    = str(date_str) \\\n",
    "                                + ',' + str(open_str) \\\n",
    "                                + ',' + str(high_str) \\\n",
    "                                + ',' + str(low_str) \\\n",
    "                                + ',' + str(close_str) \\\n",
    "                                + ',' + str(volume_str)\n",
    "                               \n",
    "                # Write the csv line to the file with a newline character:\n",
    "                csv_file.write(line_str + '\\n')\n",
    "                \n",
    "            # end of all records\n",
    "            lg('Done Writing(' + str(total_recs) + ') Output(' + str(output_file) + ')', 6)\n",
    "        # end of writing output file\n",
    "\n",
    "    except Exception as e:\n",
    "        lg('ERROR: Failed to extract Stock(' + str(ticker) + ') Records with Ex(' + str(e) + ')', 0)\n",
    "    # end of try/ex\n",
    "\n",
    "# end of db_extract_stock_records\n",
    "\n",
    "# Specify to connect the core to the redis server\n",
    "# running inside the container and listening on port 6000\n",
    "os.environ['ENV_DEPLOYMENT_TYPE'] = 'Test'\n",
    "\n",
    "# Initialize the core that will connect to the other containers\n",
    "core = PyCore()\n",
    "\n",
    "# Extract and transform the records into a csv file\n",
    "db_extract_stock_records(core, ticker, days_back, output_file)\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    lg('Success File exists: ' + str(output_file), 5)\n",
    "    \n",
    "    lg('')\n",
    "    lg('--------------------------------------------', 2)\n",
    "    lg('')\n",
    "\n",
    "    csv_file = output_file\n",
    "    lg('Processing ' + str(ticker) + ' data stored in CSV(' + str(csv_file) + ')', 6)\n",
    "    \n",
    "    # Start loading the data\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    \n",
    "    %matplotlib inline\n",
    "    import numpy as np\n",
    "    lg('Reading CSV with Pandas')\n",
    "    # handle date formats and the special tab-character on the header row with utf-8-sig\n",
    "    dateparse = lambda x: pd.datetime.strptime(x, '%d-%b-%y')\n",
    "    data = pd.read_csv(csv_file, parse_dates=[0], date_parser=dateparse, encoding='utf-8-sig') \\\n",
    "                 .sort_values(by='Date', ascending=False)\n",
    "    \n",
    "    lg('')\n",
    "    lg('Data Head with Sticks(' + str(len(data)) + ')', 1)\n",
    "    print data.head()\n",
    "    \n",
    "    lg('', 6)\n",
    "    lg('-------------------------------------------------', 2)\n",
    "    lg('Creating Ticker(' + str(ticker) + ') Plot by Close Prices', 2)\n",
    "    lg('', 6)\n",
    "    \n",
    "    # Set the size of the figure\n",
    "    plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "    \n",
    "    all_dates   = data.columns.values[0]\n",
    "    all_highs   = data.columns.values[2]\n",
    "    all_closes  = data.columns.values[4]\n",
    "    lg('Plotting the Data X-axis(' + str(all_dates) + ') Y-axis(' + str(all_closes) + ')', 5)\n",
    "\n",
    "    # Plot lines by referencing the dataframe keys \n",
    "    fig, ax    = plt.subplots()\n",
    "    max_cell   = len(data['Date']) - 1\n",
    "    start_date = str(data['Date'][0].strftime('%Y-%M-%d'))\n",
    "    end_date   = str(data['Date'][max_cell].strftime('%Y-%M-%d'))\n",
    "    ax.set_title(ticker + ' Pricing from ' + str(start_date) + ' to ' + str(end_date))\n",
    "    \n",
    "    plt.plot(data['Date'], data['High'],  color='red',    label='High')\n",
    "    plt.plot(data['Date'], data['Low'],   color='green',  label='Low')\n",
    "    plt.plot(data['Date'], data['Close'], color='blue',   label='Close')\n",
    "    plt.plot(data['Date'], data['Open'],  color='orange', label='Open')\n",
    "    \n",
    "    # Now add the legend with some customizations.\n",
    "    legend = ax.legend(loc='upper left', shadow=True, bbox_to_anchor=(0, 1.0))\n",
    "\n",
    "    # The frame is matplotlib.patches.Rectangle instance surrounding the legend.\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "    \n",
    "    lg('', 6)\n",
    "    lg('-------------------------------------------------', 2)\n",
    "    lg('', 6)\n",
    "    \n",
    "    # connect the core to the redis cache if it exists\n",
    "    cache_key = 'LATEST_' + ticker + '_DAILY_STICKS'\n",
    "    lg('Converting to JSON')\n",
    "    json_data_rec = data.to_json()\n",
    "    cache_this    = {\n",
    "                      'Ticker' : ticker,\n",
    "                      'Data'   : json_data_rec\n",
    "                  }\n",
    "    lg('Caching the Ticker(' + ticker + ') Candlesticks')\n",
    "    results  = core.purge_and_cache_records_in_redis(core.m_rds['CACHE'], cache_key, cache_this)\n",
    "\n",
    "    lg('')\n",
    "    lg('-------------------------------------------------', 2)\n",
    "    lg('')\n",
    "    \n",
    "    # confirm we can retrieve the cached data without removing it from the cache:\n",
    "    lg('Retrieving Cached Ticker(' + ticker + ') Candlesticks')\n",
    "    cache_record  = core.get_cache_from_redis(core.m_rds['CACHE'], cache_key)\n",
    "    lg('')\n",
    "\n",
    "    # the core will return a dictionary where the 'Status' == 'SUCCESS' when it was able to pull records\n",
    "    # records out of redis. After checking the 'Status', the dataset is stored under the 'Record' key.\n",
    "    if cache_record['Status'] == 'SUCCESS':\n",
    "        rec        = cache_record['Record']\n",
    "        cache_data = rec['Data']\n",
    "        sticks     = pd.read_json(cache_data).sort_values(by='Date', ascending=False)\n",
    "        lg(' - SUCCESS found cached records for Ticker(' + str(rec['Ticker']) + ')', 5)\n",
    "        lg('')\n",
    "        lg(' - Data Head with Sticks(' + str(len(sticks)) + ')')\n",
    "        print sticks.head()\n",
    "    else:\n",
    "        lg('ERROR: Failed to retreive Cached Candlesticks', 0)\n",
    "    # end of retrieving cache example\n",
    "\n",
    "    lg('')\n",
    "    \n",
    "else:\n",
    "    lg('Failed to Extract File', 0)\n",
    "# did the extraction work or not\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
