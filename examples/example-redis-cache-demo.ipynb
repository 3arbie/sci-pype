{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Jupyter + Redis Data Pipeline\n",
    "\n",
    "This extends the SPY pricing demo (example-spy-downloader.ipynb) and publishes + retreives the pricing data by using a targeted ```CACHE``` redis server (that runs inside the Jupyter container). It stores the Pandas dataframe as JSON in the ```LATEST_SPY_DAILY_STICKS``` redis key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "\n",
    "sys.path.insert(0, os.getenv('ENV_PYTHON_SRC_DIR', '/opt/work/src'))\n",
    "\n",
    "from pycore import PyCore\n",
    "\n",
    "# Specify to connect the core to the redis server\n",
    "# running inside the container and listening on port 6000\n",
    "os.environ['ENV_DEPLOYMENT_TYPE'] = 'JustRedis'\n",
    "\n",
    "print 'Initializing Python Core'\n",
    "\n",
    "core = PyCore()\n",
    "core.lg('')\n",
    "\n",
    "# the downloader is hardcoded for now to download to this shared volume + file location:\n",
    "csv_file = '/opt/work/data/src/spy.csv'\n",
    "\n",
    "# removing previous csv file if it exists\n",
    "if os.path.exists(csv_file):\n",
    "    core.lg(' - Removing Previous(' + str(csv_file) + ')', 4)\n",
    "    os.system('rm -f ' + str(csv_file) + ')')\n",
    "# end of removing previous\n",
    "\n",
    "downloader_name    = 'download-spy-csv.py'\n",
    "path_to_downloader = os.getenv('ENV_BINS', '/opt/work/bins/') + '/' + downloader_name\n",
    "\n",
    "core.lg('Downloading latest SPY Pricing with Download(' + str(path_to_downloader) + ')', 1)\n",
    "os.system(path_to_downloader)\n",
    "\n",
    "core.lg('')\n",
    "core.lg('Checking CSV is Ready')\n",
    "if os.path.exists(csv_file):\n",
    "    core.lg('  SUCCESS - File Exists: ' + str(csv_file), 5)\n",
    "    core.lg('')\n",
    "    \n",
    "    # Start loading the data\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    \n",
    "    %matplotlib inline\n",
    "    import numpy as np\n",
    "    core.lg('Reading CSV with Pandas')\n",
    "    # handle date formats and the special tab-character on the header row with utf-8-sig\n",
    "    dateparse = lambda x: pd.datetime.strptime(x, '%d-%b-%y')\n",
    "    data = pd.read_csv(csv_file, parse_dates=[0], date_parser=dateparse, encoding='utf-8-sig').sort_values(by='Date', ascending=False)\n",
    "    \n",
    "    core.lg('')\n",
    "    core.lg('Data Head with Sticks(' + str(len(data)) + ')', 1)\n",
    "    print data.head()\n",
    "    \n",
    "    core.lg('')\n",
    "    core.lg('-------------------------------------------------', 2)\n",
    "    core.lg('')\n",
    "    \n",
    "    # connect the core to the redis cache if it exists\n",
    "    cache_key = 'LATEST_SPY_DAILY_STICKS'\n",
    "    core.lg('Converting to JSON')\n",
    "    json_data_rec = data.to_json()\n",
    "    cache_this    = {\n",
    "                      'Ticker' : 'SPY',\n",
    "                      'Data'   : json_data_rec\n",
    "                  }\n",
    "    core.lg('Caching the Latest SPY Candlesticks')\n",
    "    results  = core.purge_and_cache_records_in_redis(core.m_rds['CACHE'], cache_key, cache_this)\n",
    "\n",
    "    core.lg('')\n",
    "    core.lg('-------------------------------------------------', 2)\n",
    "    core.lg('')\n",
    "    \n",
    "    # confirm we can retrieve + remove the cached data from this key:\n",
    "    core.lg('Retrieving Cached SPY Candlesticks')\n",
    "    cache_record  = core.get_message_no_block(core.m_rds['CACHE'], cache_key)\n",
    "    core.lg('')\n",
    "\n",
    "    # the core will return a dictionary where the 'Status' == 'SUCCESS' when it was able to pull records\n",
    "    # records out of redis. After checking the 'Status', the dataset is stored under the 'Record' key.\n",
    "    if cache_record['Status'] == 'SUCCESS':\n",
    "        rec        = cache_record['Record']\n",
    "        cache_data = rec['Data']\n",
    "        sticks     = pd.read_json(cache_data).sort_values(by='Date', ascending=False)\n",
    "        core.lg(' - SUCCESS found cached records for Ticker(' + str(rec['Ticker']) + ')', 5)\n",
    "        core.lg('')\n",
    "        core.lg(' - Data Head with Sticks(' + str(len(sticks)) + ')')\n",
    "        print sticks.head()\n",
    "    else:\n",
    "        core.lg('ERROR: Failed to retreive Cached Candlesticks', 0)\n",
    "    # end of retrieving cache example\n",
    "\n",
    "    core.lg('')\n",
    "else:\n",
    "    core.lg('  ERROR: Failed to find CSV(' + str(csv_file) + ')', 0)\n",
    "# end of if/else download was successful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
